# 章末测验

1. 情感数据集包含带有情感标签的 Twitter 消息。 在 Hub 中搜索它，并读取数据集卡片。 以下哪一项不是它的基本情绪之一？ 

- Joy
- Love
- **Confusion**
-  Surprise

2. 在 Hub 中搜索 ar_sarcasm 数据集。 它支持哪个任务？ 

- **Sentiment classification** 
- Machine translation 
- Named entity recognition 
- Question answering

3. BERT 模型如何期望处理一对句子 

- Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 
- [CLS] Tokens_of_sentence_1 Tokens_of_sentence_2 
- **[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 [SEP]** 
- [CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2

4. Dataset.map 方法有什么好处？ 

- **函数的结果被缓存，所以如果我们重新执行代码不会花费任何时间。**  
- **它可以应用多处理比在数据集的每个元素上应用函数更快。**  
- **它不会将整个数据集加载到内存中，而是在处理一个元素后立即保存结果。** 

5. 动态填充是什么意思？ 

- 这是当您将每个批次的输入填充到整个数据集中的最大长度时。  
- **这是当您在创建批次时填充输入时，达到该批次内句子的最大长度。**  
- 当您填充输入时，每个句子都与数据集中的前一个句子具有相同数量的标记。 

6. (collate function)的目的是什么？ 

- 它确保数据集中的所有序列具有相同的长度。  
- **它将所有样品放在一起。**  
- 它预处理整个数据集。  
- 它截断数据集中的序列。 

7. 当您使用预训练的语言模型（例如 bert-base-uncased）实例化一个 AutoModelForXxx 类时会发生什么，该模型对应于不同于它被训练的任务？

- 什么都没有，但你会收到警告。  
- **丢弃预训练模型的头部，代之以插入适合该任务的新头部。**  
- 丢弃预训练模型的头部。  
- 没什么，因为模型仍然可以针对不同的任务进行微调。 

> 例如，当我们使用 AutoModelForSequenceClassification 和 bert-base-uncased 时，我们在实例化模型时收到警告。 预训练的头部不用于序列分类任务，因此它被丢弃并使用随机权重实例化新的头部。 

8. TrainingArguments 的目的是什么？ 

- **它包含用于使用 Trainer 进行训练和评估的所有超参数。**  
- 它指定模型的大小。 
- 它只包含用于评估的超参数。  
- 它只包含用于训练的超参数。 

9. 为什么要使用 🤗 Accelerate 库？ 

- 它提供了对更快模型的访问。 
- 它提供了一个高级 API，因此我不必实现自己的训练循环。  
- **它使我们的训练循环适用于分布式策略** 。
- 它提供了更多的优化功能。 .

下一章是分享模型和分词器，这里就不往下写了。