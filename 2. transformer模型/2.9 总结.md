# 总结

在本章中，您看到了如何使用高级 🤗 Transformers 管道 API 来处理不同的 NLP 任务。 您还了解了如何在 Hub 中搜索和使用模型，以及如何使用推理 API 直接在浏览器中测试模型。

我们讨论了 Transformer 模型如何在高层次上工作，并讨论了迁移学习和微调的重要性。 一个关键方面是，您可以使用完整架构，也可以仅使用编码器或解码器，具体取决于您要解决的任务类型。 下表总结了这一点：

| Model           | Examples                                   | Tasks                                                        |
| --------------- | ------------------------------------------ | ------------------------------------------------------------ |
| Encoder         | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa | Sentence classification, named entity recognition, extractive question answering |
| Decoder         | CTRL, GPT, GPT-2, Transformer XL           | Text generation                                              |
| Encoder-decoder | BART, T5, Marian, mBART                    | Summarization, translation, generative question answering    |

