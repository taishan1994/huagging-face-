# Transformers是怎么工作的

在本节中，我们将深入了解 Transformer 模型的架构。

## 一点Transformer的历史

以下是 Transformer 模型（简短）历史中的一些参考点：

![A brief chronology of Transformers models.](https://huggingface.co/course/static/chapter1/transformers_chrono.png)

The [Transformer architecture](https://arxiv.org/abs/1706.03762) 于 2017 年 6 月推出。原始研究的重点是翻译任务。 随后推出了几个有影响力的模型，包括：

- **June 2018**: [GPT](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf), 第一个预训练的 Transformer 模型，用于对各种 NLP 任务进行微调并获得最先进的结果
- **October 2018**: [BERT](https://arxiv.org/abs/1810.04805), 另一个大型预训练模型，该模型旨在生成更好的句子摘要（下一章将详细介绍！）
- **February 2019**: [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), GPT 的改进（和更大）版本，由于道德问题没有立即公开发布
- **October 2019**: [DistilBERT](https://arxiv.org/abs/1910.01108), BERT 的提炼版本，速度提高了 60%，内存减少了 40%，并且仍然保留了 BERT 的 97% 的性能
- **October 2019**: [BART](https://arxiv.org/abs/1910.13461) and [T5](https://arxiv.org/abs/1910.10683), 两个使用与原始 Transformer 模型相同架构的大型预训练模型（第一个这样做）
- **May 2020**, [GPT-3](https://arxiv.org/abs/2005.14165), 更大版本的 GPT-2，无需微调即可在各种任务上表现良好（称为*零样本学习*）

这个列表远非全面，只是为了突出一些不同类型的 Transformer 模型。 大体上，它们可以分为三类：

-  类 GPT（也称为自回归 Transformer 模型）
-  类 BERT（也称为自编码 Transformer 模型） 
- BART/T5 类（也称为序列到序列的 Transformer 模型）

稍后我们将更深入了解这些家庭。

## Transformers是语言模型

上面提到的所有 Transformer 模型（GPT、BERT、BART、T5 等）都被训练为语言模型。 这意味着他们已经以自我监督的方式接受了大量原始文本的训练。 自监督学习是一种训练类型，其中目标是根据模型的输入自动计算的。 这意味着不需要人类来标记数据！

这种类型的模型可以对其所训练的语言进行统计理解，但对于特定的实际任务并不是很有用。 因此，通用的预训练模型会经历一个称为迁移学习的过程。 在此过程中，模型在给定任务上以监督方式进行微调——即使用人工标注的标签。

任务的一个例子是预测一个句子中已经阅读了 n 个前一个单词的下一个单词。 这被称为因果语言建模，因为输出取决于过去和现在的输入，而不是未来的输入。

![Example of causal language modeling in which the next word from a sentence is predicted.](https://huggingface.co/course/static/chapter1/causal_modeling.png)

另一个例子是掩码语言建模，其中模型预测句子中的掩码词。

![Example of masked language modeling in which a masked word from a sentence is predicted.](https://huggingface.co/course/static/chapter1/masked_modeling.png)

## Transformers是大型模型

除了一些另辟蹊径的模型（如 DistilBERT）外，实现更好性能的一般策略是增加模型的大小以及预训练的数据量。

![Number of parameters of recent Transformers models](https://huggingface.co/course/static/chapter1/model_parameters.png)

不幸的是，训练模型，尤其是大型模型，需要大量数据。 这在时间和计算资源方面变得非常昂贵。 它甚至会转化为环境影响，如下图所示。

![The carbon footprint of a large language model.](https://huggingface.co/course/static/chapter1/carbon_footprint.png)

想象一下，如果每次研究团队、学生组织或公司想要训练一个模型，它都会从头开始。 这将导致巨大的、不必要的全球成本！

这就是共享语言模型是至关重要的原因：共享已训练的权重并在已训练权重的基础上进行构建，可降低社区的整体计算成本和碳足迹。

## 迁移学习

预训练是从头开始训练模型：权重随机初始化，训练在没有任何先验知识的情况下开始。

![The pretraining of a language model is costly in both time and money.](https://huggingface.co/course/static/chapter1/pretraining.png)

这种预训练通常是在非常大量的数据上完成的。 因此，它需要非常大的数据语料库，并且训练可能需要长达数周的时间。

另一方面，微调是在模型经过预训练后进行的训练。 要进行微调，您首先需要获得一个预训练的语言模型，然后使用特定于您的任务的数据集进行额外的训练。 等等——为什么不直接为最终任务训练呢？ 有几个原因：

- 预训练模型已经在与微调数据集有一些相似之处的数据集上进行了训练。 因此，微调过程能够利用初始模型在预训练期间获得的知识（例如，对于 NLP 问题，预训练模型将对您用于任务的语言有某种统计理解）。
- 由于预训练模型已经在大量数据上进行了训练，因此微调需要更少的数据就能获得不错的结果。
- 出于同样的原因，获得良好结果所需的时间和资源要少得多。

例如，可以利用在英语语言上训练的预训练模型，然后在 arXiv 语料库上对其进行微调，从而产生基于科学/研究的模型。 微调只需要有限数量的数据：预训练模型获得的知识是可以“迁移”的，因此称为迁移学习。

![The fine-tuning of a language model is cheaper than pretraining in both time and money.](https://huggingface.co/course/static/chapter1/finetuning.png)

因此，微调模型具有更低的时间、数据、财务和环境成本。 迭代不同的微调方案也更快、更容易，因为训练比完全预训练的约束更少。

这个过程也会比从头开始训练获得更好的结果（除非你有大量数据），这就是为什么你应该总是尝试利用预训练模型——一个尽可能接近你手头任务的模型——并进行微调它。

## 一般架构

在本节中，我们将介绍 Transformer 模型的一般架构。 如果您不了解某些概念，请不要担心； 后面有详细的部分介绍了每个组件。

### 介绍

模型主要由两部分组成：

- 编码器（左边）：编码器接收输入并构建它的表示（其特征）。 这意味着模型经过优化以理解输入。
- 解码器（右边）：解码器使用编码器的表示（特征）和其他输入来生成目标序列。 这意味着模型针对生成输出进行了优化。

<img src="https://huggingface.co/course/static/chapter1/transformers_blocks.png" width="300">

这些部分中的每一个都可以独立使用，具体取决于任务：

- 仅编码器模型：适用于需要理解输入的任务，例如句子分类和命名实体识别。
- 仅解码器模型：适用于生成任务，例如文本生成。
- 编码器-解码器模型或序列到序列模型：适用于需要输入的生成任务，例如翻译或摘要。

我们将在后面的部分中独立深入研究这些架构。

### 注意力层

Transformer 模型的一个关键特征是它们由称为注意力层的特殊层构建而成。 事实上，介绍 Transformer 架构的论文的标题是[“Attention Is All You Need”](https://arxiv.org/abs/1706.03762)！ 我们将在课程后面探索注意力层的细节； 现在，您需要知道的是，该层将告诉模型在处理每个单词的表示时，特别注意您传递给它的句子中的某些单词（并或多或少忽略其他单词）。

为了将其置于上下文中，请考虑将文本从英语翻译成法语的任务。 鉴于输入“你喜欢这门课程”，翻译模型还需要注意相邻的单词“You”以获得单词“like”的正确翻译，因为在法语中动词“like”的共轭取决于主题。 然而，句子的其余部分对于该词的翻译没有用处。 同样，在翻译“this”时，模型还需要注意“course”这个词，因为“this”的翻译取决于相关名词是阳性还是阴性。 同样，句子中的其他单词对于“this”的翻译无关紧要。 对于更复杂的句子（和更复杂的语法规则），模型需要特别注意可能出现在句子中较远的单词以正确翻译每个单词。

相同的概念适用于与自然语言相关的任何任务：一个词本身就具有含义，但该含义深受上下文的影响，上下文可以是正在研究的单词之前或之后的任何其他单词（或多个单词）。

现在您已经了解了注意力层的全部内容，让我们仔细看看 Transformer 架构。

### 最原始的架构

Transformer 架构最初是为翻译而设计的。在训练期间，编码器接收某种语言的输入（句子），而解码器接收所需目标语言的相同句子。在编码器中，注意力层可以使用句子中的所有单词（因为，正如我们刚刚看到的，给定单词的翻译可以依赖于句子中在它之后和之前的内容）。然而，解码器是按顺序工作的，并且只能关注它已经翻译的句子中的单词（因此，只有当前生成的单词之前的单词）。例如，当我们预测了翻译目标的前三个单词时，我们将它们提供给解码器，然后解码器使用编码器的所有输入来尝试预测第四个单词。

为了在训练过程中加快速度（当模型可以访问目标句子时），整个目标j句子被输入到解码器中，但不允许使用未来的词。例如，当尝试预测第四个单词时，注意力层只能访问位置 1 到 3 中的单词。

最初的 Transformer 架构是这样的，左边是编码器，右边是解码器：

![Architecture of a Transformers models](https://huggingface.co/course/static/chapter1/transformers.png)

请注意，解码器块中的第一个注意力层关注解码器的所有（过去）输入，但第二个注意力层使用编码器的输出。 因此，它可以访问整个输入句子以最好地预测当前单词。 这非常有用，因为不同的语言可以有将单词按不同顺序排列的语法规则，或者句子后面提供的某些上下文可能有助于确定给定单词的最佳翻译。 注意力掩码也可以用在编码器/解码器中，以防止模型注意一些特殊的词——例如，特殊的填充词用于在将句子批处理时使所有输入具有相同的长度。 

## 架构和检查点

当我们在本课程中深入研究 Transformer 模型时，您会看到提及到架构、检查点以及模型。 这些术语的含义略有不同：

- 架构：这是模型的骨架——每一层的定义和模型中发生的每个操作。
- 检查点：这些是将在给定架构中加载的权重。
- 模型：这是一个总称，不像“架构”或“检查点”那样精确：它可以同时表示两者。 当需要减少歧义时，本课程将指定架构或检查点。

例如，BERT 是一种架构，而 bert-base-cased（谷歌团队为 BERT 的第一个版本训练的一组权重）是一个检查点。 但是，可以说“BERT 模型”和“基于 bert 的模型”。