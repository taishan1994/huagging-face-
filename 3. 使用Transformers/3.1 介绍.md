# 介绍

之前，我们使用高级管道 API 将 Transformer 模型用于不同的任务。 尽管此 API 功能强大且方便，但了解其内部工作原理很重要，这样我们才能灵活地解决其他问题。 

在本章中，您将学习：

- 如何使用分词器和模型来复制管道 API 的行为。
- 如何加载和保存模型和分词器。
- 不同的分词方法，例如基于词、基于字符和基于子词。
- 如何处理不同长度的多个句子。

Transformer 模型通常非常大。拥有数百万到数百亿的参数，训练和部署这些模型是一项复杂的工作。此外，由于几乎每天都会发布新模型并且每个模型都有自己的实现，因此尝试所有这些模型并非易事。

🤗 Transformers 库就是为了解决这个问题而创建的。它的目标是提供一个单一的 API，通过它可以加载、训练和保存任何 Transformer 模型。该库的主要特点是：

- 易于使用：只需两行代码即可下载、加载和使用最先进的 NLP 模型进行推理。
- 灵活性：从本质上讲，所有模型都是简单的 PyTorch nn.Module 或 TensorFlow tf.keras.Model 类，并且可以像其各自机器学习 (ML) 框架中的任何其他模型一样进行处理。
- 简单性：在整个库中几乎没有任何抽象。 “一体化文件”是一个核心概念：模型的前向传递完全定义在单个文件中，因此代码本身是可理解和可破解的。

最后一个功能使 🤗 Transformers 与其他 ML 库完全不同。模型不是建立在跨文件共享的模块上的；相反，每个模型都有自己的层。除了使模型更易于理解和破解外，这还使您可以轻松地在一个模型上进行试验，而不会影响其他模型。

本章将从一个端到端的例子开始，我们使用一个模型和一个分词器来复制第 2章中介绍的管道 API。接下来，我们将讨论模型 API：我们将深入研究模型和配置类，并向您展示如何加载模型以及它如何处理数值输入以输出预测。

然后我们将查看分词器 API，它是管道的另一个主要组件。分词器负责第一个和最后一个处理步骤，处理神经网络从文本到数字输入的转换，以及在需要时转换回文本。最后，我们将向您展示如何在一个准备好的批次中通过模型处理发送多个句子，然后仔细研究高级分词器函数来总结它。